{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Topic Modelling Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is another personal project of mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThese commands have been run in the JupyterLab console:\\n\\npip install praw \\n\\npip install stop_words\\n\\npip install nltk\\n\\nNOTE: We install these modules specifically using pip here because Conda version is\\noutdated. A seperate Conda environment was created to avoid package management issues.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "These commands have been run in the JupyterLab console:\n",
    "\n",
    "pip install praw \n",
    "\n",
    "pip install stop_words\n",
    "\n",
    "pip install nltk\n",
    "\n",
    "NOTE: We install these modules specifically using pip here because Conda version is\n",
    "outdated. A seperate Conda environment was created to avoid package management issues.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnltk.download('stopwords')\\nnltk.download('punkt')\\n\\nDownload the stopwords and punkt resource for nltk if necessary\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import praw as praw #import praw package for streaming content from Reddit\n",
    "\n",
    "#import the following packages for the following praw program in the next cell\n",
    "import random  \n",
    "import socket\n",
    "import sys\n",
    "#DONE#\n",
    "\n",
    "#Import the following packages for the text preprocessor function\n",
    "import string #import string module for string manipulation\n",
    "import stop_words #import base stop_words \n",
    "import nltk #import nltk for removing extra stop words and tokenising strings for text preprocessor function\n",
    "\n",
    "from stop_words import get_stop_words #(About 900 stop words)\n",
    "from nltk.corpus import stopwords #(An extra 150 stop words)\n",
    "from nltk.tokenize import word_tokenize #(tokeniser function)\n",
    "\n",
    "'''\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "Download the stopwords and punkt resource for nltk if necessary\n",
    "'''\n",
    "#DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go here while logged into the account you want to create a token for: https://www.reddit.com/prefs/apps/\n",
      "Click the create an app button. Put something in the name field and select the script radio button.\n",
      "Put http://localhost:8080 in the redirect uri field and click create app\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the client ID, it's the line just under Personal use script at the top:  93b74cYiSei-YQ\n",
      "Enter the client secret, it's the line next to secret:  uUqBxVmcwVAqsYZ-fov-3v4srA3QuA\n",
      "Now enter a comma separated list of scopes, or all for all tokens:  all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now open this url in your browser: https://www.reddit.com/api/v1/authorize?client_id=93b74cYiSei-YQ&duration=permanent&redirect_uri=http%3A%2F%2Flocalhost%3A8080&response_type=code&scope=%2A&state=24021\n",
      "Refresh token: 690585682570-JQjcILiuobzxHE-06Qe8lTD17Sio3w\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Code taken from praw documentation to initiate program to obtain refresh token for Reddit API\n",
    "authorisation. This is necessary to avoid using personal username and password for\n",
    "authentication.\n",
    "'''\n",
    "def receive_connection():\n",
    "    \"\"\"Wait for and then return a connected socket..\n",
    "\n",
    "    Opens a TCP connection on port 8080, and waits for a single client.\n",
    "\n",
    "    \"\"\"\n",
    "    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "    server.bind((\"localhost\", 8080))\n",
    "    server.listen(1)\n",
    "    client = server.accept()[0]\n",
    "    server.close()\n",
    "    return client\n",
    "\n",
    "\n",
    "def send_message(client, message):\n",
    "    \"\"\"Send message to client and close the connection.\"\"\"\n",
    "    print(message)\n",
    "    client.send(f\"HTTP/1.1 200 OK\\r\\n\\r\\n{message}\".encode(\"utf-8\"))\n",
    "    client.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Provide the program's entry point when directly executed.\"\"\"\n",
    "    print(\n",
    "        \"Go here while logged into the account you want to create a token for: \"\n",
    "        \"https://www.reddit.com/prefs/apps/\"\n",
    "    )\n",
    "    print(\n",
    "        \"Click the create an app button. Put something in the name field and select the\"\n",
    "        \" script radio button.\"\n",
    "    )\n",
    "    print(\"Put http://localhost:8080 in the redirect uri field and click create app\")\n",
    "    client_id = input(\n",
    "        \"Enter the client ID, it's the line just under Personal use script at the top: \"\n",
    "    )\n",
    "    client_secret = input(\"Enter the client secret, it's the line next to secret: \")\n",
    "    commaScopes = input(\n",
    "        \"Now enter a comma separated list of scopes, or all for all tokens: \"\n",
    "    )\n",
    "\n",
    "    if commaScopes.lower() == \"all\":\n",
    "        scopes = [\"*\"]\n",
    "    else:\n",
    "        scopes = commaScopes.strip().split(\",\")\n",
    "\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=client_id.strip(),\n",
    "        client_secret=client_secret.strip(),\n",
    "        redirect_uri=\"http://localhost:8080\",\n",
    "        user_agent=\"praw_refresh_token_example\",\n",
    "    )\n",
    "    state = str(random.randint(0, 65000))\n",
    "    url = reddit.auth.url(scopes, state, \"permanent\")\n",
    "    print(f\"Now open this url in your browser: {url}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    client = receive_connection()\n",
    "    data = client.recv(1024).decode(\"utf-8\")\n",
    "    param_tokens = data.split(\" \", 2)[1].split(\"?\", 1)[1].split(\"&\")\n",
    "    params = {\n",
    "        key: value for (key, value) in [token.split(\"=\") for token in param_tokens]\n",
    "    }\n",
    "\n",
    "    if state != params[\"state\"]:\n",
    "        send_message(\n",
    "            client,\n",
    "            f\"State mismatch. Expected: {state} Received: {params['state']}\",\n",
    "        )\n",
    "        return 1\n",
    "    elif \"error\" in params:\n",
    "        send_message(client, params[\"error\"])\n",
    "        return 1\n",
    "\n",
    "    refresh_token = reddit.auth.authorize(params[\"code\"])\n",
    "    send_message(client, f\"Refresh token: {refresh_token}\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(main())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = \"\", \n",
    "                                   client_secret = \"\",\n",
    "                                  user_agent = \"\",\n",
    "                                  refresh_token = \"\"\n",
    "                                  )\n",
    "\n",
    "#Authentication credentials used above to get access to Reddit API\n",
    "#Insert generated refresh token from the previous cell into the empty parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reddit.user.me()) #check that the user login worked correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(\"ukpolitics\") #Set the subreddit of choice to stream Reddit post submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = subreddit.new(limit = 1000) #Create variable that gathers new submissions from subreddit, input integer to limit posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = [] #Create empty list to hold submission titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function that extracts submission titles from Reddit API and appends into a list.\n",
    "\n",
    "def streamer():\n",
    "\n",
    "    for submission in x:\n",
    "        title_list.append(submission.title)\n",
    "        print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "streamer() #call streamer function to create list containing submission titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to prepare text for language processing\n",
    "\n",
    "#str_list is the list that is to be converted into a string\n",
    "\n",
    "def string_preprocessor(list_2_str):\n",
    "    \n",
    "        list_2_str = str(list_2_str) #convert list into string format\n",
    "\n",
    "        list_2_str = list_2_str.lower() #change all text in string to lowercase format\n",
    "\n",
    "        list_2_str = list_2_str.translate(str.maketrans(\"\", \"\", string.punctuation)) #remove all punctuation from string\n",
    "\n",
    "        list_2_str = list_2_str.strip() #remove all whitespace from string\n",
    "\n",
    "        return(list_2_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = string_preprocessor(title_list) #input your list to be converted here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) #create stop words object from nltk stopwords resource\n",
    "subreddit_tokens = word_tokenize(title_list) #Create word tokens from title_list by merging title_list with word_tokenize resource from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_tokens_str = str(subreddit_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
